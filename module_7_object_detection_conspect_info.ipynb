{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/petroDavydov/goit-DeepLearningForComputerVisionAndNLP/blob/main/module_7_object_detection_conspect_info.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-juTBjFrXQv"
   },
   "source": [
    "# ***From Conspect Example Topic 7***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-acGorrrwzJ"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade ultralytics\n",
    "!pip install --upgrade -U ray[tune]\n",
    "!apt-get install tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQlXnv-wr2mZ"
   },
   "source": [
    "**import of necessary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bj-URSiUsC4x"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import random\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import seaborn as sns\n",
    "\n",
    "# import IPython.display as display\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "!wandb disabled # use if you have Weights and Biases installed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-Exyq1dGtrt"
   },
   "source": [
    "Тека з даними має таку структуру:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jxWYUIyUGuiI"
   },
   "outputs": [],
   "source": [
    "!tree /content/drive/MyDrive/DeepLearningforComputervisionandNLP/css-data-object-detect -L 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNbCfKlEHH1m"
   },
   "source": [
    "Створимо клас, у якому будемо зберігати всі конфігурації, необхідні для навчання моделі."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "20uQDVF9HJHg"
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    DEBUG = True # Set to True to make quick experiments\n",
    "    FRACTION = 0.05 if DEBUG else 1.0 # Specifies the fraction of the dataset to use for training. Allows for training on a subset of the full dataset, useful for experiments or when resources are limited.\n",
    "    SEED = 42\n",
    "\n",
    "    # classes\n",
    "    CLASSES = ['Hardhat', 'Mask', 'NO-Hardhat', 'NO-Mask',\n",
    "               'NO-Safety Vest', 'Person', 'Safety Cone',\n",
    "               'Safety Vest', 'machinery', 'vehicle']\n",
    "    NUM_CLASSES_TO_TRAIN = len(CLASSES)\n",
    "\n",
    "    # training\n",
    "    EPOCHS = 3 if DEBUG else 70 # 100\n",
    "    BATCH_SIZE = 8 # 16\n",
    "\n",
    "    BASE_MODEL = 'yolov9e' # yolov8n, yolov8s, yolov8m, yolov8l, yolov8x, yolov9c, yolov9e\n",
    "    BASE_MODEL_WEIGHTS = f'{BASE_MODEL}.pt'\n",
    "    EXP_NAME = f'ppe_css_{EPOCHS}_epochs'\n",
    "\n",
    "    OPTIMIZER = 'auto' # SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto\n",
    "    LR = 1e-3\n",
    "    LR_FACTOR = 0.01 # Final learning rate as a fraction of the initial rate = (lr0 * lrf), used in conjunction with schedulers to adjust the learning rate over time.\n",
    "    WEIGHT_DECAY = 5e-4 # L2 regularization term, penalizing large weights to prevent overfitting.\n",
    "    DROPOUT = 0.0\n",
    "    PATIENCE = 20\n",
    "    PROFILE = False\n",
    "    LABEL_SMOOTHING = 0.0\n",
    "\n",
    "    # paths\n",
    "    CUSTOM_DATASET_DIR = '/content/drive/MyDrive/DeepLearningforComputervisionandNLP/css-data-object-detect/'\n",
    "    OUTPUT_DIR = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X8j_x1TIHomi"
   },
   "outputs": [],
   "source": [
    "dict_file = {\n",
    "    'train': os.path.join(CFG.CUSTOM_DATASET_DIR, 'train'),\n",
    "    'val': os.path.join(CFG.CUSTOM_DATASET_DIR, 'valid'),\n",
    "    'test': os.path.join(CFG.CUSTOM_DATASET_DIR, 'test'),\n",
    "    'nc': CFG.NUM_CLASSES_TO_TRAIN,\n",
    "    'names': CFG.CLASSES\n",
    "    }\n",
    "\n",
    "with open(os.path.join(CFG.OUTPUT_DIR, 'data.yaml'), 'w+') as file:\n",
    "    yaml.dump(dict_file, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8qm0sW_H2ob"
   },
   "outputs": [],
   "source": [
    "# read yaml file created\n",
    "def read_yaml_file(file_path = CFG.CUSTOM_DATASET_DIR):\n",
    "    with open(file_path, 'r') as file:\n",
    "        try:\n",
    "            data = yaml.safe_load(file)\n",
    "            return data\n",
    "        except yaml.YAMLError as e:\n",
    "            print(\"Error reading YAML:\", e)\n",
    "            return None\n",
    "\n",
    "# print it with newlines\n",
    "def print_yaml_data(data):\n",
    "    formatted_yaml = yaml.dump(data, default_style=False)\n",
    "    print(formatted_yaml)\n",
    "\n",
    "file_path = os.path.join(CFG.OUTPUT_DIR, 'data.yaml')\n",
    "yaml_data = read_yaml_file(file_path)\n",
    "\n",
    "if yaml_data:\n",
    "    print_yaml_data(yaml_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FfqxI4xNH6dl"
   },
   "outputs": [],
   "source": [
    "def display_image(image, print_info = True, hide_axis = False):\n",
    "    if isinstance(image, str):  # Check if it's a file path\n",
    "        img = Image.open(image)\n",
    "        plt.imshow(img)\n",
    "    elif isinstance(image, np.ndarray):  # Check if it's a NumPy array\n",
    "        image = image[..., ::-1]  # BGR to RGB\n",
    "        img = Image.fromarray(image)\n",
    "        plt.imshow(img)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported image format\")\n",
    "\n",
    "    if print_info:\n",
    "        print('Type: ', type(img), '\\\\n')\n",
    "        print('Shape: ', np.array(img).shape, '\\\\n')\n",
    "\n",
    "    if hide_axis:\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "example_image_path = CFG.CUSTOM_DATASET_DIR + '/train/images/-2297-_png_jpg.rf.9fff3740d864fbec9cda50d783ad805e.jpg'\n",
    "display_image(example_image_path, print_info = True, hide_axis = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0Ea9rxrL5lQ"
   },
   "source": [
    "Візуалізуємо декілька випадкових зображень з набору даних.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q1zb_KUvLF5l"
   },
   "outputs": [],
   "source": [
    "def plot_random_images_from_folder(folder_path, num_images=20, seed=CFG.SEED):\n",
    "\n",
    "  random.seed(seed)\n",
    "\n",
    "  # Get a list of image files in the folder\n",
    "  image_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.png', '.jpeg', '.gif'))]\n",
    "\n",
    "  # Ensure that we have at least num_images files to choose from\n",
    "  if len(image_files) < num_images:\n",
    "    raise ValueError(\"Not enough images in the folder\")\n",
    "\n",
    "  # Randomly select num_images image files\n",
    "  selected_files = random.sample(image_files, num_images)\n",
    "\n",
    "  # Create a subplot grid\n",
    "  num_cols = 5\n",
    "  num_rows = (num_images + num_cols - 1) / num_cols\n",
    "  fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 8))\n",
    "\n",
    "  for i, file_name in enumerate(selected_files):\n",
    "    # Open and display the image using PIL\n",
    "    img = Image.open(os.path.join(folder_path, file_name))\n",
    "\n",
    "    if num_rows == 1:\n",
    "      ax = axes[i % num_cols]\n",
    "    else:\n",
    "      ax = axes[i / num_cols, i % num_cols]\n",
    "\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    # ax.set_title(file_name)\n",
    "\n",
    "  # Remove empty subplots\n",
    "  for i in range(num_images, num_rows * num_cols):\n",
    "    if num_rows == 1:\n",
    "      fig.delaxes(axes[i % num_cols])\n",
    "    else:\n",
    "      fig.delaxes(axes[i / num_cols, i % num_cols])\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBUkkncKQFPb"
   },
   "source": [
    "# ***---------------------------------***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s0ACeTRrOVkT",
    "outputId": "780504af-efbd-42bc-d13d-b44375e20cce"
   },
   "outputs": [],
   "source": [
    "def get_image_properties(image_path):\n",
    "    # Read the image file\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Check if the image file is read successfully\n",
    "    if img is None:\n",
    "        raise ValueError(\"Could not read image file\")\n",
    "\n",
    "    # Get image properties\n",
    "    properties = {\n",
    "        \"width\": img.shape[1],\n",
    "        \"height\": img.shape[0],\n",
    "        \"channels\": img.shape[2] if len(img.shape) == 3 else 1,\n",
    "        \"dtype\": img.dtype,\n",
    "    }\n",
    "\n",
    "    return properties\n",
    "\n",
    "img_properties = get_image_properties(example_image_path)\n",
    "img_properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvSfdljrQPol"
   },
   "source": [
    "Ознайомимося з базовою статистикою датасету. Підрахуємо кількість представників у кожному класі за всіма вибірками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqWCcGnPQQas"
   },
   "outputs": [],
   "source": [
    "class_idx = {str(i): CFG.CLASSES[i] for i in range(CFG.NUM_CLASSES_TO_TRAIN)}\n",
    "\n",
    "class_stat = {}\n",
    "data_len = {}\n",
    "class_info = []\n",
    "\n",
    "for mode in ['train', 'valid', 'test']:\n",
    "    class_count = {CFG.CLASSES[i]: 0 for i in range(CFG.NUM_CLASSES_TO_TRAIN)}\n",
    "\n",
    "    path = os.path.join(CFG.CUSTOM_DATASET_DIR, mode, 'labels')\n",
    "\n",
    "    for file in os.listdir(path):\n",
    "        with open(os.path.join(path, file)) as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "            for cls in set([line[0] for line in lines]):\n",
    "                class_count[class_idx[cls]] += 1\n",
    "\n",
    "    data_len[mode] = len(os.listdir(path))\n",
    "    class_stat[mode] = class_count\n",
    "\n",
    "    class_info.append({'Mode': mode, **class_count, 'Data_Volume': data_len[mode]})\n",
    "\n",
    "dataset_stats_df = pd.DataFrame(class_info)\n",
    "with pd.option_context('display.max_columns', None):\n",
    "    display(dataset_stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNfP3Kv7RCXv"
   },
   "source": [
    "Візуалізуємо розподіл класів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZ0jO4U4RDUx"
   },
   "outputs": [],
   "source": [
    "# Create subplots with 1 row and 3 columns\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot vertical bar plots for each mode in subplots\n",
    "for i, mode in enumerate(['train', 'valid', 'test']):\n",
    "    sns.barplot(\n",
    "        data=dataset_stats_df[dataset_stats_df['Mode'] == mode].drop(columns='Mode'),\n",
    "        orient='v',\n",
    "        ax=axes[i],\n",
    "        palette='Set2'\n",
    "    )\n",
    "\n",
    "    axes[i].set_title(f'{mode.capitalize()} Class Statistics')\n",
    "    axes[i].set_xlabel('Classes')\n",
    "    axes[i].set_ylabel('Count')\n",
    "    axes[i].tick_params(axis='x', rotation=90)\n",
    "\n",
    "    # Add annotations on top of each bar\n",
    "    for p in axes[i].patches:\n",
    "        axes[i].annotate(f\"{int(p.get_height())}\", (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                         ha='center', va='center', fontsize=8, color='black', xytext=(0, 5),\n",
    "                         textcoords='offset points')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Xnz-z7pRKUM"
   },
   "source": [
    "Тестування базової моделі"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jqgOoGtfRK_5"
   },
   "outputs": [],
   "source": [
    "model = YOLO(CFG.BASE_MODEL_WEIGHTS)\n",
    "\n",
    "results = model.predict(\n",
    "    source = example_image_path,\n",
    "    classes = [0],\n",
    "    conf = 0.30,\n",
    "#     device = [0,1], # inference with dual GPU\n",
    "    device = None, # inference with CPU\n",
    "    imgsz = (img_properties['height'], img_properties['width']),\n",
    "    save = True,\n",
    "    save_txt = True,\n",
    "    save_conf = True,\n",
    "    exist_ok = True,\n",
    ")\n",
    "\n",
    "example_image_inference_output = example_image_path.split('/')[-1]\n",
    "display_image(f'runs/detect/predict/{example_image_inference_output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UV_wmPdORcTq"
   },
   "source": [
    "Тренування моделі"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LtYQhoCdRdpc"
   },
   "outputs": [],
   "source": [
    "model = YOLO(CFG.BASE_MODEL_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JT7WZIuRjcd"
   },
   "source": [
    "Для тренування викличемо метод .train нашої моделі. З детальним переліком аргументів цього методу можна ознайомитись на офіційній сторінці Ultralytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "re42msTVRkoR"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model.train(\n",
    "    data = os.path.join(CFG.OUTPUT_DIR, 'data.yaml'),\n",
    "\n",
    "    task = 'detect',\n",
    "\n",
    "    imgsz = (img_properties['height'], img_properties['width']),\n",
    "\n",
    "    epochs = CFG.EPOCHS,\n",
    "    batch = CFG.BATCH_SIZE,\n",
    "    optimizer = CFG.OPTIMIZER,\n",
    "    lr0 = CFG.LR,\n",
    "    lrf = CFG.LR_FACTOR,\n",
    "    weight_decay = CFG.WEIGHT_DECAY,\n",
    "    dropout = CFG.DROPOUT,\n",
    "    fraction = CFG.FRACTION,\n",
    "    patience = CFG.PATIENCE,\n",
    "    profile = CFG.PROFILE,\n",
    "    label_smoothing = CFG.LABEL_SMOOTHING,\n",
    "\n",
    "    name = f'{CFG.BASE_MODEL}_{CFG.EXP_NAME}',\n",
    "    seed = CFG.SEED,\n",
    "\n",
    "    val = True,\n",
    "    amp = True,\n",
    "    exist_ok = True,\n",
    "    resume = False,\n",
    "    device = [0], #  [0,1]\n",
    "#     device = None, # CPU run\n",
    "    verbose = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKVI6Tt2R80y"
   },
   "source": [
    "Збережемо ваги натренованої моделі."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cv-xlWNNR-Bq"
   },
   "outputs": [],
   "source": [
    "# Export the model\n",
    "model.export(\n",
    "    format = 'onnx', # openvino, onnx, engine, tflite\n",
    "    imgsz = (img_properties['height'], img_properties['width']),\n",
    "    half = False,\n",
    "    int8 = False,\n",
    "    simplify = False,\n",
    "    nms = False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNToDVzdDRpWzWMRPtbw7oQ",
   "include_colab_link": true,
   "mount_file_id": "1KWM_tEcdMQtL35Z3BFEjvgEL8sQJadz0",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
