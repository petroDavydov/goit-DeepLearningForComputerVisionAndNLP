{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/petroDavydov/goit-DeepLearningForComputerVisionAndNLP/blob/main/Topic_11__RNN_GRU_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W94fud1dWFHv"
   },
   "source": [
    "# ***Завантаження бібліотек***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qVVL58JRBu_4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import math\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Uupg1JTdj6j"
   },
   "source": [
    "Визначимо шлях до даних і пристрій, на якому будемо проводити розрахунки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YnaYUVbIdkr5"
   },
   "outputs": [],
   "source": [
    "data_path = '/content/drive/MyDrive/DeepLearningforComputervisionandNLP/conll003-englishversion/'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WSkZsXFeGVK"
   },
   "source": [
    "будемо зчитувати тільки елементи на позиції 0 — слова — і 3 — мітки іменованих сутностей. У коді це буде відображатися так: sentences.append((l[0], l[3].strip('\\\\n')))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tqx_r2AjeHLx",
    "outputId": "8b1d8c97-c14f-4acd-b339-5e84d08913b5"
   },
   "outputs": [],
   "source": [
    "def load_sentences(filepath):\n",
    "    final = []\n",
    "    sentences = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            if (line == ('-DOCSTART- -X- -X- O\\n') or line == '\\n'):\n",
    "                if len(sentences) > 0:\n",
    "                    final.append(sentences)\n",
    "                    sentences = []\n",
    "            else:\n",
    "                l = line.split(' ')\n",
    "                sentences.append((l[0], l[3].strip('\\n')))\n",
    "    return final\n",
    "\n",
    "train_sents = load_sentences(data_path + 'train.txt')\n",
    "test_sents = load_sentences(data_path + 'test.txt')\n",
    "val_sents = load_sentences(data_path + 'valid.txt')\n",
    "\n",
    "train_sents[:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "220JfECQe7uk"
   },
   "source": [
    "Визначимо список міток класів і закодуємо їх для чисельного представлення."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NzjprIUrfBbe"
   },
   "outputs": [],
   "source": [
    "ner_labels = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
    "id2label = {str(i): label for i, label in enumerate(ner_labels)}\n",
    "label2id = {value: int(key) for key, value in id2label.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmGfG98-fLb5"
   },
   "source": [
    "Представимо наші завантажені речення як словник, де під ключем text будуть зберігатися наші речення, а під ключем label — відповідні мітки іменованих сутностей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MZicRA0RfMQC"
   },
   "outputs": [],
   "source": [
    "def get_df(samples):\n",
    "    df,label = [], []\n",
    "    for lines in samples:\n",
    "        cur_line, cur_label = list(zip(*lines))\n",
    "        df.append(list(cur_line))\n",
    "        label.append([label2id[i] for i in cur_label])\n",
    "    return {'text':df, 'label':label}\n",
    "\n",
    "\n",
    "train_df = get_df(train_sents)\n",
    "test_df = get_df(test_sents)\n",
    "val_df = get_df(val_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmIVOBNLfXzu"
   },
   "source": [
    "Для подальшої роботи з даними нам потрібно представити їх у чисельній формі.\n",
    "\n",
    "Спочатку побудуємо словник. Для цього спершу підрахуємо кількість появи кожного слова в корпусі."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PihBjgX7fY5G"
   },
   "outputs": [],
   "source": [
    "word_dict = defaultdict(int)\n",
    "\n",
    "for line in train_df['text']:\n",
    "    for word in line:\n",
    "        word_dict[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMkF-04sffZI"
   },
   "source": [
    "Ми не будемо використовувати слова, які дуже рідко з’являються, для тренування. Таким чином, ми зменшимо кількість неінформативних ознак у наборі даних."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_MHicFPfgJZ"
   },
   "outputs": [],
   "source": [
    "lower_freq_word = []\n",
    "for k,v in word_dict.items():\n",
    "    if v < 2:\n",
    "        lower_freq_word.append(k)\n",
    "\n",
    "for word in lower_freq_word:\n",
    "    del word_dict[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynPdZSvMfnFS"
   },
   "source": [
    "***Додамо до словника два спеціальні токени.***\n",
    "\n",
    "Перший токен <UNK> позначатиме всі слова, які не присутні у словнику, так звані Out Of Vocabulary words, OOV words\n",
    "\n",
    "Другий токен <PAD> позначає падинг (padding). Оскільки речення в наборі даних можуть мати різну довжину, необхідно забезпечити, щоб усі вхідні послідовності мали однакову довжину для обробки батчами (batch processing). Це досягається шляхом додавання спеціальних символів — падингів — до коротших послідовностей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n1bR38OEf3mq"
   },
   "outputs": [],
   "source": [
    "word_dict['<UNK>'] = -1\n",
    "word_dict['<PAD>'] = -2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpx8a0YYf-ZU"
   },
   "source": [
    "створюємо словник, який буде містити слово та його індекс. Ми будемо використовувати цей словник, щоб представити наші речення в числовому вигляді для подальшої обробки нейронною мережею."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97kTrGI6f_ID"
   },
   "outputs": [],
   "source": [
    "word2id = {}\n",
    "\n",
    "for idx, word in enumerate(word_dict.keys()):\n",
    "  word2id[word] = idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YO-OwTEOtLOc"
   },
   "source": [
    "# ***Dataset і DataLoader***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38KbIKZFtSYD"
   },
   "source": [
    "Створимо допоміжну функцію, якою будемо кодувати речення в числовий формат. Якщо слово є в нашому словнику, ми будемо замінювати його на відповідне значення зі словника.\n",
    "\n",
    "Якщо ж слово не присутнє у словнику — будемо повертати числове значення, що позначає токен <UNK>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "csAAR9HptMwj"
   },
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = []\n",
    "    for w in seq:\n",
    "        if w in to_ix.keys():\n",
    "            idxs.append(to_ix[w])\n",
    "        else:\n",
    "            idxs.append(to_ix['<UNK>'])\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLwOMKS7tXcT"
   },
   "source": [
    "Опишемо клас Dataset, необхідний для абстракції та організації даних під час навчання моделі. Він дозволяє легко керувати даними, завантажувати їх і забезпечує доступ до окремих прикладів даних і їхніх міток."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_s7MYuS_tYo0"
   },
   "outputs": [],
   "source": [
    "class CoNLLDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.texts = df['text']\n",
    "        self.labels = df['label']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_sequence(self.texts[item], word2id)\n",
    "        label = self.labels[item]\n",
    "        return {\n",
    "            'input_ids': inputs,\n",
    "            'labels': label\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ck0v3TYwQee"
   },
   "source": [
    "Для тренування поточної моделі нам необхідно визначити collate-функцію."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "POw0GwJJwY61"
   },
   "source": [
    "Наприкінці перетворюємо наші дані в torch.tensor для подальшої роботи з фреймворком PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6Xc6J25wRH2"
   },
   "outputs": [],
   "source": [
    "class Collate:\n",
    "    def __init__(self, train):\n",
    "        self.train = train\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        output = dict()\n",
    "        output[\"input_ids\"] = [sample[\"input_ids\"] for sample in batch]\n",
    "        if self.train:\n",
    "            output[\"labels\"] = [sample[\"labels\"] for sample in batch]\n",
    "\n",
    "        # calculate max token length of this batch\n",
    "        batch_max = max([len(ids) for ids in output[\"input_ids\"]])\n",
    "\n",
    "        # add padding\n",
    "\n",
    "        output[\"input_ids\"] = [s + (batch_max - len(s)) * [word2id['<PAD>']] for s in output[\"input_ids\"]]\n",
    "        if self.train:\n",
    "            output['labels'] = [s + (batch_max - len(s)) * [-100] for s in output[\"labels\"]]\n",
    "\n",
    "        # convert to tensors\n",
    "        output[\"input_ids\"] = torch.tensor(output[\"input_ids\"], dtype=torch.long)\n",
    "        if self.train:\n",
    "            output[\"labels\"] = torch.tensor(output[\"labels\"], dtype=torch.long)\n",
    "\n",
    "        return output\n",
    "\n",
    "collate_fn = Collate(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jdFEs55OwclU"
   },
   "source": [
    "# ***Клас моделі***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfENknNZwhG4"
   },
   "source": [
    "1. embeddings — шар ембедингів.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwKG9_vOwj9s"
   },
   "source": [
    "2. lstm — шар, який відповідає за Bi-LSTM-компонент у нашій мережі.\n",
    "\n",
    "\n",
    " - embedding_dim визначає розмірність вхідних векторів.\n",
    "\n",
    " - hidden_dim визначає розмірність прихованих станів і вихідного тензора.\n",
    "\n",
    " - bidirectional робить LSTM двонаправленою.\n",
    "\n",
    " - num_layers дозволяє створити глибоку модель з трьома послідовними LSTM-шарами.\n",
    "\n",
    " - batch_first вказує, що перший розмір вхідного тензора відповідає розміру батчу, що полегшує обробку даних у батчах.\n",
    "\n",
    " - fc створює повнозв'язний (лінійний) шар.\n",
    "\n",
    " - output_size визначає кількість нейронів у вихідному шарі, що відповідає кількості класів у задачі класифікації.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13MCtrufwePI"
   },
   "outputs": [],
   "source": [
    "class BiLSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, output_size, embeddings=None):\n",
    "        super(BiLSTMTagger, self).__init__()\n",
    "\n",
    "        # 1. Embedding Layer\n",
    "        if embeddings is None:\n",
    "            self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        else:\n",
    "            self.embeddings = nn.Embedding.from_pretrained(embeddings)\n",
    "\n",
    "        # 2. LSTM Layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, num_layers=3, batch_first=True)\n",
    "\n",
    "        # 3. Dense Layer\n",
    "        self.fc = nn.Linear(2*hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, batch_text):\n",
    "\n",
    "        embeddings = self.embeddings(batch_text)\n",
    "\n",
    "        lstm_output, _ = self.lstm(embeddings)\n",
    "\n",
    "        logits = self.fc(lstm_output)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvLaTLEC7i3k"
   },
   "source": [
    "Допоміжні функції для тренування"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gaEkFOKT7nN4"
   },
   "source": [
    "Спершу визначимо функцію remove_predictions_for_masked_items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zg4p8bsV7rdC"
   },
   "source": [
    "Оскільки нас цікавить тільки якість передбачення для міток іменованих сутностей, будемо прибирати з результатів токени зі значенням, меншим за 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TN54WPGO7j2Y"
   },
   "outputs": [],
   "source": [
    "def remove_predictions_for_masked_items(predicted_labels, correct_labels):\n",
    "\n",
    "    predicted_labels_without_mask = []\n",
    "    correct_labels_without_mask = []\n",
    "\n",
    "    for p, c in zip(predicted_labels, correct_labels):\n",
    "        if c > 0:\n",
    "            predicted_labels_without_mask.append(p)\n",
    "            correct_labels_without_mask.append(c)\n",
    "\n",
    "    return predicted_labels_without_mask, correct_labels_without_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7s_8y5yo7-TB"
   },
   "source": [
    "Тепер визначимо функцію, відповідальну за навчання й валідацію. Як валідаційну метрику використаємо macro F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d7Lvd2Ez7-8B"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, batch_size, max_epochs, num_batches, patience, output_path):\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=-100)  # we mask the <pad> labels\n",
    "    optimizer = Adam(model.parameters())\n",
    "\n",
    "    train_f_score_history = []\n",
    "    dev_f_score_history = []\n",
    "    no_improvement = 0\n",
    "    for epoch in range(max_epochs):\n",
    "\n",
    "        total_loss = 0\n",
    "        predictions, correct = [], []\n",
    "        model.train()\n",
    "        for batch in tqdm(train_loader, total=num_batches, desc=f\"Epoch {epoch}\"):\n",
    "\n",
    "            cur_batch_size, text_length = batch['input_ids'].shape\n",
    "\n",
    "            pred = model(batch['input_ids'].to(device)).view(cur_batch_size*text_length, NUM_CLASSES)\n",
    "            gold = batch['labels'].to(device).view(cur_batch_size*text_length)\n",
    "\n",
    "            loss = criterion(pred, gold)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, pred_indices = torch.max(pred, 1)\n",
    "\n",
    "            predicted_labels = list(pred_indices.cpu().numpy())\n",
    "            correct_labels = list(batch['labels'].view(cur_batch_size*text_length).numpy())\n",
    "\n",
    "            predicted_labels, correct_labels = remove_predictions_for_masked_items(predicted_labels,\n",
    "                                                                                   correct_labels)\n",
    "\n",
    "            predictions += predicted_labels\n",
    "            correct += correct_labels\n",
    "\n",
    "        train_score = f1_score(correct, predictions, average=\"macro\")\n",
    "        train_f_score_history.append(train_score)\n",
    "\n",
    "        print(\"Total training loss:\", total_loss)\n",
    "        print(\"Training Macro F1:\", train_score)\n",
    "\n",
    "        total_loss = 0\n",
    "        predictions, correct = [], []\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "\n",
    "                cur_batch_size, text_length = batch['input_ids'].shape\n",
    "\n",
    "                pred = model(batch['input_ids'].to(device)).view(cur_batch_size*text_length, NUM_CLASSES)\n",
    "                gold = batch['labels'].to(device).view(cur_batch_size*text_length)\n",
    "\n",
    "                loss = criterion(pred, gold)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                _, pred_indices = torch.max(pred, 1)\n",
    "                predicted_labels = list(pred_indices.cpu().numpy())\n",
    "                correct_labels = list(batch['labels'].view(cur_batch_size*text_length).numpy())\n",
    "\n",
    "                predicted_labels, correct_labels = remove_predictions_for_masked_items(predicted_labels,\n",
    "                                                                                       correct_labels)\n",
    "\n",
    "                predictions += predicted_labels\n",
    "                correct += correct_labels\n",
    "\n",
    "        dev_score = f1_score(correct, predictions, average=\"macro\")\n",
    "\n",
    "        print(\"Total validation loss:\", total_loss)\n",
    "        print(\"Validation Macro F1:\", dev_score)\n",
    "\n",
    "        dev_f = dev_score\n",
    "        if len(dev_f_score_history) > patience and dev_f < max(dev_f_score_history):\n",
    "            no_improvement += 1\n",
    "\n",
    "        elif len(dev_f_score_history) == 0 or dev_f > max(dev_f_score_history):\n",
    "            print(\"Saving model.\")\n",
    "            torch.save(model, output_path)\n",
    "            no_improvement = 0\n",
    "\n",
    "        if no_improvement > patience:\n",
    "            print(\"Validation F-score does not improve anymore. Stop training.\")\n",
    "            dev_f_score_history.append(dev_f)\n",
    "            break\n",
    "\n",
    "        dev_f_score_history.append(dev_f)\n",
    "\n",
    "    return train_f_score_history, dev_f_score_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10rjdtX68H5i"
   },
   "source": [
    "☝ Зверніть увагу, тут ми додаємо механізм ранньої зупинки тренування."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6nvbyMi8K84"
   },
   "source": [
    "Визначимо функцію для тестування"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BH66EkbW8Iqo"
   },
   "outputs": [],
   "source": [
    "def test(model, test_iter, batch_size, labels, target_names):\n",
    "    total_loss = 0\n",
    "    predictions, correct = [], []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch in test_iter:\n",
    "\n",
    "            cur_batch_size, text_length = batch['input_ids'].shape\n",
    "\n",
    "            pred = model(batch['input_ids'].to(device)).view(cur_batch_size*text_length, NUM_CLASSES)\n",
    "            gold = batch['labels'].to(device).view(cur_batch_size*text_length)\n",
    "\n",
    "            _, pred_indices = torch.max(pred, 1)\n",
    "            predicted_labels = list(pred_indices.cpu().numpy())\n",
    "            correct_labels = list(batch['labels'].view(cur_batch_size*text_length).numpy())\n",
    "\n",
    "            predicted_labels, correct_labels = remove_predictions_for_masked_items(predicted_labels,\n",
    "                                                                                   correct_labels)\n",
    "\n",
    "            predictions += predicted_labels\n",
    "            correct += correct_labels\n",
    "\n",
    "    print(classification_report(correct, predictions, labels=labels, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_ve4PGLBelC"
   },
   "source": [
    "# ***Тренування моделі***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1xoXKCcBi9s"
   },
   "source": [
    "Спершу визначимо гіперпараметри моделі."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUNKukFkBfuU"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 64\n",
    "NUM_CLASSES = len(id2label)\n",
    "MAX_EPOCHS = 50\n",
    "PATIENCE = 3\n",
    "BATCH_SIZE = 32\n",
    "VOCAB_SIZE = len(word2id)\n",
    "OUTPUT_PATH = \"/tmp/bilstmtagger\"\n",
    "num_batches = math.ceil(len(train_df) / BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4h-F2Mm9Bxxn"
   },
   "source": [
    "Створимо об’єкти Dataset і DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QVEk944NBz8e"
   },
   "outputs": [],
   "source": [
    "train_dataset = CoNLLDataset(train_df)\n",
    "val_dataset = CoNLLDataset(val_df)\n",
    "test_dataset = CoNLLDataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              collate_fn=collate_fn,\n",
    "                              num_workers=4,\n",
    "                              pin_memory=True,\n",
    "                              drop_last=False)\n",
    "\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=False,\n",
    "                              collate_fn=collate_fn,\n",
    "                              num_workers=4,\n",
    "                              pin_memory=True,\n",
    "                              drop_last=False)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=False,\n",
    "                              collate_fn=collate_fn,\n",
    "                              num_workers=4,\n",
    "                              pin_memory=True,\n",
    "                              drop_last=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8gZyNCdB2r6"
   },
   "source": [
    "Створимо об’єкт моделі."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CirXa3AsB3QW",
    "outputId": "3842c772-2bc0-412f-8253-c638161130c3"
   },
   "outputs": [],
   "source": [
    "tagger = BiLSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, VOCAB_SIZE+2, NUM_CLASSES)\n",
    "tagger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DiD2VaCzB-qN"
   },
   "source": [
    "# ***Нарешті, переходимо до тренування!***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "a07dde6b7395468da35c0069d8897c3c",
      "b8db9a5d62c3483db1d8dc4120006ae9",
      "5bdf8b224daf4febac07da700772a8e2",
      "93e990d7f30345dfa97b129fca2fe13e",
      "8b8917a919c848cdbbc73d162c4658e1",
      "f1ccaa1674014914aa5edd98650459d9",
      "5674afc444f344c98b7e85d07ec36870",
      "117c445491644c79b442d4120a0409bd",
      "fcddc3298b3742da81995e2e95a66ccb",
      "474c9f2cff494c2e872c970ae54ffbcd",
      "4d3600e124be491cb678c2293203938c",
      "dcd57e8726a54363a422178da20f4199",
      "711ac9427528449c8bb1167b347851da",
      "ff8fe4e8a090426dbaa275fa18465dbc",
      "4690acfabd1e453eb7227f0408108df5",
      "ce41d4edc2b94eb993217806d8fa0569",
      "88bdbf0b7b2940a79f846cde4dfcdca7",
      "75c2810f73014a51ae479bf245a7c9b1",
      "c3553c6f4873444cb975c9ebe2fd2188",
      "d41bb6ed04784c3e93dd4df432872384",
      "a0898104f0d84c8493300fb03cbdfaf1",
      "b88076952b1b4784b22af5f88e546efb",
      "e0d45b302354464aa75790d7ff148787",
      "45c391752a8c43d08ec5c2ed86aa8762",
      "b17b0caa546945cfbd4d1dff456c67db",
      "1405e71353cb4671badc0f2a1eb8fd15",
      "63213e473cc7480cbfaafa951a011d73",
      "46b771d919c84129abcb4706291e4d1f",
      "2feac38d57a447ba876a849529002a44",
      "eccc840e5f4d469ab999ed5ad1001462",
      "c3a142ff43b44f1aa221a86afe308882",
      "57a532541c8d4e9aacb16d163653f917",
      "4aeb627585184bffbd5584d4168f76e0",
      "fed489841e0c402dae1bd05e81a59f43",
      "9d5c88aa902747778ad661e8935a5e81",
      "71f667589085434f83e5b30be05e542b",
      "b308fcacf15a406aadb84ffe7f5f5546",
      "3a8dd5755ae14231b5a0099b36c02a6e",
      "0f5df38f5f5b4d0abb870e9f06c6b122",
      "c877ec90b5f84101a6f5bd19d0cde600",
      "34a9769221eb43d6a2557b64184010de",
      "9d8631bcd4754b829d3928919c36000f",
      "b144e97be7a44e77befad42454257f9d",
      "00350222d8bd46878175d3000451d255",
      "329cc981ec3646a19f8d2e64f1dd2b56",
      "52930a69086348cb9b9889f821bd5dae",
      "3bbf69aa7bd247a98b17395d499fec35",
      "de838103c1f44f6ca5fc254d40e9fba3",
      "807b5aec77034a00926fc2dc623a0642",
      "c202aded2ac44e418bf78e1c66015081",
      "2a77ef04be7a4e7d87af6a4764ebbca6",
      "adbc09022ea84896abccf2dba7d9aeef",
      "a6ab8209c9f34e3798eff98a1387f033",
      "2c68626728e14b389675c1e26ffde883",
      "2d0519abe4a34e8a9247fa74cf29bcd5",
      "8ce0a12db1fe4b58a58738ecd166c833",
      "b41b31b4179f442aae5ab275c97ce744",
      "caf126fe7c1045e492b45bf64d00cf7b",
      "e1c1c19e1636405c9f1939e2bf5b4470",
      "f7fbbdb6c9844ed18b13cd760a16bd22",
      "efed47ba11fb49a5ad6045279d49fcea",
      "3ac320d04bab4ede840d26ba5cc13fba",
      "4adafa430eca4e23a05270987e91fb6f",
      "5e10003579d8455a9c6d1b03ed4135b0",
      "b4822138354c4293b26830566b4a3f16",
      "f49d39c188344db4b950a914698987db",
      "7199b255f009467ea1e8c7f1656e2e4d",
      "5402be95640c4c44aba1a8634d79ce40",
      "e22b95f083cd41e0a8824d495f173d5b",
      "f01d997ad07e46c7990f6e1afd70e429",
      "8e0408b6a3fc44cd8eaebe01a42425de",
      "4ffd9433fbd24b8a96a639722dae63d9",
      "9e32cddd83f04d0caa3c6df169efe50d",
      "5b62765e562c4fc0a377805af87e95b1",
      "8dbae9b8195f4465a6dfabcc5d7f6cb8",
      "c835486c938042b187d0ba7e7d7ff060",
      "40eb2615f6d04223aee93e71a5fbc281",
      "583f4b4993454bdb87dac03f62d7b295",
      "8b61209b0be948a7989d5a2cb9b45684",
      "fdd5264521b44df09b3db473b2a8bdea",
      "0c4ef988b90c44d6a80d58e693b377e6",
      "8acd4c5d42684f60931033b9efd26f7e",
      "c0256319463842e0be65a158c3a50073",
      "80016a8a8ad24f3281d1d2ab8673ba11",
      "c3864581606a4c02841eb23cbe8f377f",
      "ed2bbbdf90e04e1f8699fb72811922cf",
      "36a3818ea82042d4a96966b6a9ca498a",
      "54235ff383a54ab9bd27d60518c32e9e",
      "b88c3b1225ef448f916a5e1a80eb9b54",
      "81c68f7b6eff435888091f1ad67d57ce",
      "b0fcbd8cd0074c9e919c0ae54fdb12bf",
      "5de940f9b74749479cdbd1f109757053",
      "349a7166340c42e2bfcf49793ed4773b",
      "6a8a4cfa4b4742f09d008cb50b558dde",
      "6f710cef5d3041e08103c6e82e8e02e7",
      "a86adaef75324b6cb08a493c3822b0d2",
      "8d58750334454524971bf3be68bed299",
      "c304f505ca42422bb8ed74908ca1fa39",
      "e46cbdff40064eba819b4e332cbf7f97"
     ]
    },
    "id": "Ea-bm9LjB_TC",
    "outputId": "2cbd8210-1f36-4ea5-edd2-2171fa4c0655"
   },
   "outputs": [],
   "source": [
    "train_f, dev_f = train(tagger.to(device), train_loader, val_loader, BATCH_SIZE, MAX_EPOCHS,\n",
    "                       num_batches, PATIENCE, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSWidqrWC2GM"
   },
   "source": [
    "Візуалізуємо навчальну й валідаційну метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "id": "1ZpzUPIIC3um",
    "outputId": "f45403da-4ccc-4e75-adc3-31146f31124b"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'epochs': range(0,len(train_f)),\n",
    "                  'train_f1': train_f,\n",
    "                   'dev_f1': dev_f})\n",
    "\n",
    "plt.plot('epochs', 'train_f1', data=df, color='blue', linewidth=2)\n",
    "plt.plot('epochs', 'dev_f1', data=df, color='green', linewidth=2)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0tdb8JzC6xW"
   },
   "source": [
    "Перевіримо якість моделі на тестовому наборі даних. Завантажимо кращу зі збережених моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bTAHq-9PC7XG"
   },
   "outputs": [],
   "source": [
    "tagger = torch.load(OUTPUT_PATH, weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIv3d94LDA3t"
   },
   "source": [
    "Виконаємо перевірку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1jFkfUEnDBpg",
    "outputId": "2fed5a6d-f477-403a-cf8b-976738620ee6"
   },
   "outputs": [],
   "source": [
    "labels = list(label2id.keys())[1:]\n",
    "label_idxs = list(label2id.values())[1:]\n",
    "\n",
    "test(tagger, test_loader, BATCH_SIZE, labels = label_idxs, target_names = labels)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO+WvKzEbmM8Y+GFuTdZKp3",
   "include_colab_link": true,
   "mount_file_id": "1LHAMpkralFd0Otc9SMSIFQaHxK0M2QQK",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
