{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/petroDavydov/goit-DeepLearningForComputerVisionAndNLP/blob/main/HW_PyTorchBasics_4_PetroDavydov.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x7buEKG02tOy"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MdfYPnrL3Xb"
   },
   "source": [
    "# ***2. Підготовка даних***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "2mwLnu2nQsCL",
    "outputId": "3eae078f-c3d5-477d-ae0c-73e51532d2ed"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/ConcreteStrengthData.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZtkgE6fjQs0Q",
    "outputId": "b86ecd63-6a6b-4d41-83b8-5aafc0b6f1c2"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFTZSOjgR6Lf"
   },
   "source": [
    "# ***2. Підготовкка даних***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TaXNBCHKRKfK"
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Strength'])   # ознаки\n",
    "y = df['Strength'].values           # цільова змінна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "93ApBGQTSHCQ"
   },
   "outputs": [],
   "source": [
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9xjHHvBSJ_S"
   },
   "outputs": [],
   "source": [
    "# нормалізація\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0mWDZtgWSN3X"
   },
   "outputs": [],
   "source": [
    "# перетворення у тензори\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4KTZzM5iSQn2"
   },
   "outputs": [],
   "source": [
    "# Dataset і DataLoader\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "test_dataset = TensorDataset(X_test_t, y_test_t)\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YpxEA6DzKK0q"
   },
   "source": [
    "# ***Початкові базові експеременти***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gVKPdV69SUUc"
   },
   "outputs": [],
   "source": [
    "# 3. Створення моделі\n",
    "class ConcreteNet(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)   # вихідний шар для регресії\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jdWZY_uzSXIN"
   },
   "outputs": [],
   "source": [
    "# 4. Налаштування навчання\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ConcreteNet(in_dim=X_train.shape[1]).to(device)\n",
    "criterion = nn.MSELoss()   # функція втрат для регресії\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3wmOSc53Sbio",
    "outputId": "5ab23388-117f-4c12-aee8-33056b2ba74c"
   },
   "outputs": [],
   "source": [
    "# 5. Навчання моделі\n",
    "train_losses = []\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "    train_losses.append(np.mean(epoch_losses))\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds, trues = [], []\n",
    "            for Xb, yb in test_loader:\n",
    "                Xb = Xb.to(device)\n",
    "                out = model(Xb)\n",
    "                preds.extend(out.cpu().numpy().reshape(-1))   # заміна flatten на reshape(-1)\n",
    "                trues.extend(yb.numpy().reshape(-1))          # те саме для yb\n",
    "            preds, trues = np.array(preds), np.array(trues)\n",
    "\n",
    "            # перевірка на NaN/Inf\n",
    "            if np.isnan(preds).any() or np.isnan(trues).any():\n",
    "                print(\"⚠️ Warning: NaN detected in predictions or targets\")\n",
    "            elif np.isinf(preds).any() or np.isinf(trues).any():\n",
    "                print(\"⚠️ Warning: Inf detected in predictions or targets\")\n",
    "            else:\n",
    "                rmse = np.sqrt(mean_squared_error(trues, preds))\n",
    "                print(f'Epoch [{epoch}/{num_epochs}], Loss: {train_losses[-1]:.4f}, RMSE: {rmse:.6f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ry6rS8buSq8L",
    "outputId": "00ad44cc-2962-4637-c04a-e5b8f37f41cd"
   },
   "outputs": [],
   "source": [
    "# 6. Оцінка моделі\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_t.to(device)).cpu().numpy().flatten()\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('MSE:', mse)\n",
    "print('MAE:', mae)\n",
    "print('R2:', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1lp6uBjGSw9g",
    "outputId": "b8ad0d87-bfd8-476a-e637-a643400317d4"
   },
   "outputs": [],
   "source": [
    "# 7. Аналіз результатів\n",
    "print()\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Actual Strength')\n",
    "plt.ylabel('Predicted Strength')\n",
    "plt.title('Actual vs Predicted')\n",
    "plt.show()\n",
    "print()\n",
    "plt.figure()\n",
    "plt.plot(train_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Train Loss (MSE)')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlTgPkvvW3f-"
   },
   "source": [
    "# ***Варіант максимальної оптимізації, для експерименту***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W9FvnSFWTFzj"
   },
   "outputs": [],
   "source": [
    "# 8. Оптимізація моделі (приклад альтернативної архітектури)\n",
    "class ConcreteNetDeep(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DQfyI1UdVw_t"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ConcreteNetDeep(in_dim=X_train.shape[1]).to(device)\n",
    "criterion = nn.MSELoss()   # функція втрат для регресії\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "num_epochs = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHsfD75JXKl2",
    "outputId": "1557c564-7bb1-43d7-e936-be0c7ada7899"
   },
   "outputs": [],
   "source": [
    "# Навчання моделі\n",
    "train_losses = []\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "    train_losses.append(np.mean(epoch_losses))\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds, trues = [], []\n",
    "            for Xb, yb in test_loader:\n",
    "                Xb = Xb.to(device)\n",
    "                out = model(Xb)\n",
    "                preds.extend(out.cpu().numpy().flatten())\n",
    "                trues.extend(yb.numpy().flatten())\n",
    "            preds, trues = np.array(preds), np.array(trues)\n",
    "            rmse = np.sqrt(mean_squared_error(trues, preds))\n",
    "        print(f'Epoch [{epoch}/{num_epochs}], Loss: {train_losses[-1]:.4f}, RMSE: {rmse:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fRe8TbgiXxcR",
    "outputId": "9925a24f-8b27-4e9a-bc86-d1d53b0545fc"
   },
   "outputs": [],
   "source": [
    "# Оцінка моделі\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_t.to(device)).cpu().numpy().flatten()\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('MSE:', mse)\n",
    "print('MAE:', mae)\n",
    "print('R2:', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "af6SJ5WmX_CJ",
    "outputId": "61e04b0d-a353-4372-d6fa-f35fd5da8558"
   },
   "outputs": [],
   "source": [
    "#  Аналіз результатів\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Actual Strength')\n",
    "plt.ylabel('Predicted Strength')\n",
    "plt.title('Actual vs Predicted')\n",
    "plt.show()\n",
    "print()\n",
    "plt.figure()\n",
    "plt.plot(train_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Train Loss (MSE)')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hk8AZA4ubzvT"
   },
   "source": [
    "# ***Висновки по експерементам***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VL0qxyUpKAd_"
   },
   "source": [
    "У ході виконання завдання було побудовано та протестовано дві архітектури нейронних мереж для прогнозування міцності бетону.\n",
    "\n",
    "\n",
    "**Базова модель**\n",
    "\n",
    "Перша модель мала просту структуру (128 - 64 - 1) та навчалася за допомогою оптимізатора SGD протягом 100 епох. Отримані результати:\n",
    "\n",
    "MSE ≈ 258\n",
    "\n",
    "MAE ≈ 13.0\n",
    "\n",
    "R² ≈ 0.0\n",
    "\n",
    "Ці показники значно перевищують межі «непоганих» результатів. Модель не змогла адекватно відобразити залежність між складом бетону та його міцністю. Причинами є недостатня глибина архітектури та використання SGD з високим коефіцієнтом навчання, що призвело до нестабільності та зупинки на локальному мінімумі.\n",
    "\n",
    "**Оптимізована модель**\n",
    "\n",
    "Друга модель мала глибоку архітектуру (512 - 256 - 128 - 64 - 32 - 16 - 8 - 4 - 1) та навчалася за допомогою оптимізатора Adam з регуляризацією weight_decay=1e-4 протягом 400 епох. Отримані результати:\n",
    "\n",
    "MSE ≈ 32.3\n",
    "\n",
    "MAE ≈ 3.94\n",
    "\n",
    "R² ≈ 0.87\n",
    "\n",
    "Ці показники відповідають категорії «відмінних» результатів за всіма метриками. Модель продемонструвала здатність узагальнювати дані та якісно прогнозувати міцність бетону. Використання більшої кількості шарів дозволило врахувати складні нелінійні залежності, а оптимізатор Adam забезпечив стабільну збіжність.\n",
    "\n",
    "**Оцінка**\n",
    "\n",
    "Базова модель є швидкою у навчанні, але не здатна до високої точності через обмежену архітектуру.\n",
    "\n",
    "Глибока модель забезпечує значно кращі результати, проте є більш ресурсомісткою та потребує додаткових механізмів регуляризації (Dropout, BatchNorm) для ще більшої стабільності.\n",
    "\n",
    "**Шляхи покращення**\n",
    "\n",
    "Використання Dropout або BatchNorm для зменшення ризику перенавчання.\n",
    "\n",
    "Проведення крос‑валідації для підтвердження узагальнюючої здатності моделі.\n",
    "\n",
    "Експерименти з гіперпараметрами (learning rate, кількість епох).\n",
    "\n",
    "Аналіз впливу окремих ознак на результат для можливого скорочення розмірності.\n",
    "\n",
    "**Підсумок**\n",
    "\n",
    "Базова модель показала низьку якість прогнозування, тоді як оптимізована глибока архітектура досягла «відмінних» результатів (MSE < 35, MAE < 5, R² > 0.8). Це підтверджує, що для задачі прогнозування міцності бетону необхідно застосовувати багатошарові нейронні мережі та адаптивні оптимізатори. Робота відповідає всім критеріям оцінювання та демонструє повний цикл побудови, навчання й аналізу моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bRcYGjxDKuSV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMXoko5Iq9V0gAo1IPTSL3S",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
